{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction 1\n",
    "\n",
    "__Week 2 - 4 May 2022__\n",
    "\n",
    "Practice applying and using dimensionality rediuction for analysing datasets with Principal Component Analysis (`PCA` & `Kernel PCA`).\n",
    "\n",
    "---\n",
    "### Data\n",
    "\n",
    "The dataset is a photometric catalogue of galaxies. These galaxies were found in the 2-square degree field on the sky called COSMOS by space- and ground-based telescopes.\n",
    "\n",
    "The radiation flux (energy per second) of each galaxy is measured in 8 bands (i.e. wavelengths of light) that span the spectrum from <span style=\"color:blue;\">blue</span> to <span style=\"color:rgb(192,4,1,1);\">infrared</span>: `u, r, z++, yHSC, H, Ks, SPLASH1, SPLASH2`. The fluxes are not corrected for any effects, such as distance to a galaxy, therefore there is a systematic effect in their measurements (called redshift).\n",
    "\n",
    "So, in addition to its photometry each galaxy has its observed bias and physical properties:\n",
    "* `redshift`$^1$ - systematic bias in flux measurements.\n",
    "* `log_mass` - stellar mass in units of $log_{10}$ (inferred from a combination of fluxes and redshifts).\n",
    "* `log_sfr` - rate of star formation in units of $log_{10}$ (inferred from a combination of fluxes and redshifts).\n",
    "* `is_star_forming` - classification, based on galaxy colours (inferred from a combinations of fluxes and redshifts).\n",
    "\n",
    "<span style=\"font-size:0.9em;\"> $^1$ - redshift is the reddening of light that is proportianal to the velocity of an object receding away. On the sky, object velocities are proportional to their distances from us ([find out more](https://www.anisotropela.dk/encyclo/redshift.html)). </span>\n",
    "\n",
    "---\n",
    "### Exercise\n",
    "\n",
    "Analyze the galaxy catalogue applying dimensionality reduction to galaxy fluxes.\n",
    "\n",
    "* Apply `PCA` to fluxes. Can you find a base of principal compoenents that separates galaxies into star forming and dead? Does PCA give you a way to differentiate between various properties of galaxies?\n",
    "* Think about preprocessing the data, if you haven't yet, and see if you can find a more representative set of principal components.\n",
    "* Apply `Kernel PCA` afterwards. Does this give you a more meaningful vector space? If so, why?\n",
    "* Apply `t-SNE`. Does it give you a cleaner separation between objects with different properties?\n",
    "* Apply `UMAP`, for comparison.\n",
    "\n",
    "---\n",
    "* Authors:  Vadim Rusakov, Charles Steinhardt\n",
    "* Email:  vadim.rusakov@nbi.ku.dk\n",
    "* Date:   27th of April 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"datasets/cosmos2015.csv\"\n",
    "df = pd.read_csv(file, index_col=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a random sub-sample of the dataset. `PCA` does computations linearly, therefore it's quick and you can choose the whole dataset if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a random sub-sample of the dataset\n",
    "n = 10000\n",
    "idxs = np.arange(df.shape[0])\n",
    "idxs_rand = np.random.choice(idxs, size=n)\n",
    "df_cut = df.iloc[idxs_rand] # dataframe\n",
    "X = df.iloc[idxs_rand].values # array\n",
    "\n",
    "flux_cols = list(df.columns[4:]) # flux column names\n",
    "flux_idxs = np.argwhere(np.isin(df.columns, flux_cols)).flatten() # flux column indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)\n",
    "\n",
    "Now take the galaxy data (fluxes) and find out whether you can reduce it to a couple of meaningful principal components using `PCA`. By meaningful, we are interested in the method that is capable of separating galaxies into `star forming` or `dead`.\n",
    "\n",
    "Use the following parameters: `n_components=2`. The user interface of the PCA in sklearn is the same as for all other similar classes (see PCA [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)).\n",
    "\n",
    "You can access training data (only fluxes columns) as `X[:, flux_idxs]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA() # get a pca object of class PCA()\n",
    "y_pcs = pca.fit_transform() # train pca object on fluxes (raw observed data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure\n",
    "fig, ax = plt.subplots(1, figsize=(5, 5), dpi=100)\n",
    "ax.set_xlim(np.percentile(y_pcs[:,0], 99), np.percentile(y_pcs[:,0], 1))\n",
    "ax.set_ylim(np.percentile(y_pcs[:,1], 99), np.percentile(y_pcs[:,1], 1))\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "is_sf = np.isin(df_cut.loc[:, 'is_star_forming'], 1) # is a galaxy forming stars, i.e. alive?\n",
    "\n",
    "# scatter plot using two principal components stored in y_pcs\n",
    "ax.scatter(y_pcs[is_sf, 0], y_pcs[is_sf, 1], s=0.02, c='b', norm=LogNorm())\n",
    "ax.scatter(y_pcs[~is_sf, 0], y_pcs[~is_sf, 1], s=0.02, c='r', norm=LogNorm())\n",
    "ax.annotate(\"star forming\", xy=(0.05, 0.9), xycoords=\"axes fraction\", \n",
    "            color='b', fontsize=12)\n",
    "ax.annotate(\"dead\", xy=(0.05, 0.86), xycoords=\"axes fraction\", \n",
    "            color='r', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make scatter plots coloured by different galaxy properties: `log_mass`, `log_sfr`, `redshift`. Is the low-dimensional representation meaningful in any one of the properties? Can you argue why?\n",
    "\n",
    "Below is an example code for colouring the scatter by some property, eg., `log_mass`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6, 5), dpi=100)\n",
    "ax.set_xlim(np.percentile(y_pcs[:,0], 99), np.percentile(y_pcs[:,0], 1))\n",
    "ax.set_ylim(np.percentile(y_pcs[:,1], 99), np.percentile(y_pcs[:,1], 1))\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "\n",
    "sc = ax.scatter(y_pcs[:,0], y_pcs[:,1], s=0.2, \n",
    "                c=df_cut.loc[:, 'log_mass'], cmap='jet', norm=LogNorm())\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.ax.set_ylabel('Mass', rotation=270, labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel PCA\n",
    "\n",
    "For now, let us continue throwing these data at other algorithms to get some practice with them. `KernelPCA` is a variant of the PCA, which can use a range of kernels for non-linear operations. I.e., this extension gives flexibility in separating the data that are not linearly-separable.\n",
    "\n",
    "Use the following parameters: `n_components=2`, `kernel='cosine'`. Make sure to try different kernels for reducing the dimensionality. See documentation for `KernelPCA` in **sklearn**.\n",
    "\n",
    "For Kernel PCA see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html#sklearn.decomposition.KernelPCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca = KernelPCA()\n",
    "y_pcs = kpca.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(5, 5), dpi=100)\n",
    "ax.set_xlim(np.percentile(y_pcs[:,0], 99), np.percentile(y_pcs[:,0], 1))\n",
    "ax.set_ylim(np.percentile(y_pcs[:,1], 99), np.percentile(y_pcs[:,1], 1))\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "is_sf = np.isin(df_cut.loc[:, 'is_star_forming'], 1) # is a galaxy forming stars, i.e. alive?\n",
    "\n",
    "ax.scatter(y_pcs[is_sf, 0], y_pcs[is_sf, 1], s=0.02, c='b', norm=LogNorm())\n",
    "ax.scatter(y_pcs[~is_sf, 0], y_pcs[~is_sf, 1], s=0.02, c='r', norm=LogNorm())\n",
    "ax.annotate(\"star forming\", xy=(0.05, 0.9), xycoords=\"axes fraction\", \n",
    "            color='b', fontsize=12)\n",
    "ax.annotate(\"dead\", xy=(0.05, 0.86), xycoords=\"axes fraction\", \n",
    "            color='r', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Again, make scatter plots coloured by different galaxy properties: `log_mass`, `log_sfr`, `redshift`. Is the low-dimensional representation more meaningful with this algorithm? Can you argue why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6, 5), dpi=100)\n",
    "ax.set_xlim(np.percentile(y_pcs[:,0], 99), np.percentile(y_pcs[:,0], 1))\n",
    "ax.set_ylim(np.percentile(y_pcs[:,1], 99), np.percentile(y_pcs[:,1], 1))\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "\n",
    "sc = ax.scatter(y_pcs[:,0], y_pcs[:,1], s=0.2, norm=LogNorm(),\n",
    "                c=df_cut.loc[:, 'redshift'], cmap='jet')\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.ax.set_ylabel('Redshift', rotation=270, labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try to run `t-SNE` on the dataset (for examples or set-up see documentation for `t-SNE` on sklearn [website](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)). Use `perplexity=50, method='barnes_hut', n_iter=1000, random_state=42, verbose=2` for now. In the next class we will put more emphasis on the importance of the optimal values for theses parameters.\n",
    "\n",
    "* How well does `t-SNE` help to differentiate between two classes here?\n",
    "\n",
    "* Do you get clusters of galaxies or a continuum?\n",
    "\n",
    "* Which physical property is the most distinctly separated in the reduced space (again, use colouring of scatter to analyze this)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running t-SNE\n",
    "tsne = TSNE()\n",
    "y = tsne.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6, 5), dpi=100)\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "is_sf = np.isin(df_cut.loc[:, 'is_star_forming'], 1)\n",
    "\n",
    "ax.scatter(y[is_sf, 0], y[is_sf, 1], s=0.05, c='b', norm=LogNorm())\n",
    "ax.scatter(y[~is_sf, 0], y[~is_sf, 1], s=0.05, c='r', norm=LogNorm())\n",
    "ax.annotate(\"star forming\", xy=(0.05, 0.9), xycoords=\"axes fraction\", \n",
    "            color='b', fontsize=12)\n",
    "ax.annotate(\"dead\", xy=(0.05, 0.86), xycoords=\"axes fraction\", \n",
    "            color='r', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6, 5), dpi=100)\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "\n",
    "sc = ax.scatter(y[:,0], y[:,1], s=0.2, norm=LogNorm(),\n",
    "                c=df_cut.loc[:, 'redshift'], cmap='jet')\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.ax.set_ylabel('Redshift', rotation=270, labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6, 5), dpi=100)\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "\n",
    "sc = ax.scatter(y[:,0], y[:,1], s=0.2, norm=LogNorm(),\n",
    "                c=df_cut.loc[:, 'log_mass'], cmap='jet')\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.ax.set_ylabel('Mass', rotation=270, labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6, 5), dpi=100)\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "\n",
    "sc = ax.scatter(y[:,0], y[:,1], s=0.2, norm=LogNorm(),\n",
    "                c=df_cut.loc[:, 'log_sfr'], cmap='jet')\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.ax.set_ylabel('SFR', rotation=270, labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP\n",
    "\n",
    "Now try using `UMAP`. For documentation see the UMAP [webpage](https://umap-learn.readthedocs.io/en/latest/api.html). This has the same interface as the other embedding classes above. Use with `n_components=2, n_neighbors=50, random_state=42`. \n",
    "\n",
    "* Do you get something similar to `t-SNE`?\n",
    "\n",
    "* How well can you map different properties in the reduced space?\n",
    "\n",
    "* Do you get clusters or continuous distributions? Which physical property is the most strongly separable with `UMAP`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = umap.UMAP()\n",
    "y = map.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(5, 5), dpi=100)\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "is_sf = np.isin(df_cut.loc[:, 'is_star_forming'], 1)\n",
    "\n",
    "ax.scatter(y[is_sf, 0], y[is_sf, 1], s=0.02, c='b', norm=LogNorm())\n",
    "ax.scatter(y[~is_sf, 0], y[~is_sf, 1], s=0.02, c='r', norm=LogNorm())\n",
    "ax.annotate(\"star forming\", xy=(0.05, 0.9), xycoords=\"axes fraction\", \n",
    "            color='b', fontsize=12)\n",
    "ax.annotate(\"dead\", xy=(0.05, 0.86), xycoords=\"axes fraction\", \n",
    "            color='r', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6, 5), dpi=100)\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "\n",
    "sc = ax.scatter(y[:,0], y[:,1], s=0.2, norm=LogNorm(),\n",
    "                c=df_cut.loc[:, 'redshift'], cmap='jet')\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.ax.set_ylabel('Redshift', rotation=270, labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6, 5), dpi=100)\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "\n",
    "sc = ax.scatter(y[:,0], y[:,1], s=0.2, norm=LogNorm(),\n",
    "                c=df_cut.loc[:, 'log_mass'], cmap='jet')\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.ax.set_ylabel('Mass', rotation=270, labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(6, 5), dpi=100)\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "\n",
    "sc = ax.scatter(y[:,0], y[:,1], s=0.2, norm=LogNorm(),\n",
    "                c=df_cut.loc[:, 'log_sfr'], cmap='jet')\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.ax.set_ylabel('SFR', rotation=270, labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5875523c0f295e9a7a392db41a9a428ae2dda35a82a766a28c29c1f8950fbf4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
