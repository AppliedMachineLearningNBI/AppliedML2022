{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hyperparameter Optimization Example\n",
    "\n",
    "This Jupyter Notebook is made for illustrating - through a mixture of slides and code in an interactive fashion - the different methods for optimising Hyperparameters for Machine Learning models. First it shows the most naive, manual approach, then grid search, and finally bayesian optimization. \n",
    "\n",
    "\n",
    "### Authors and Date:\n",
    "- Christian Michelsen & Troels Petersen (Niels Bohr Institute)   \n",
    "- 2022-05-01 (latest update)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This notebook uses the __[HTRU2 Pulsar dataset](https://archive.ics.uci.edu/ml/datasets/HTRU2)__ dataset as example data for Hyperparameter Optimization (HPO).\n",
    "\n",
    "The focus on this small example is neither the actual code nor getting any specific results, but - hopefully - getting a better understanding of HPO. This is also why we don't describe the code in great detail - and simply load the dataset from a csv file directly - but the first part of the code should hopefully look familiar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Naive, manual approach\n",
    "2. Grid search\n",
    "3. Random search\n",
    "4. Bayesian optimization\n",
    "5. \"Full\" scan over parameter space\n",
    "6. New methods\n",
    "7. New software\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- __[HTRU2 Pulsar dataset](https://archive.ics.uci.edu/ml/datasets/HTRU2)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Focus on the understanding of HPO, not the actual code nor the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Nomenclature (i.e. naming scheme)\n",
    "- Machine Learning Model: $\\mathcal{A}$\n",
    "- $N$ hyperparameters\n",
    "- Domain: $\\Lambda_n$\n",
    "- Hyperparameter configuration space: $\\mathbf{\\Lambda}=\\Lambda_1 \\times \\Lambda_2 \\times \\dots \\times \\Lambda_N $\n",
    "- Vector of hyperparameters: $\\mathbf{\\lambda} \\in \\mathbf{\\Lambda}$\n",
    "- Specific ML model: $\\mathcal{A}_\\mathbf{\\lambda}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Domain of hyperparameters:\n",
    "\n",
    "1. real\n",
    "2. integer\n",
    "3. binary\n",
    "4. categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Goal:\n",
    "\n",
    "Given a dataset $\\mathcal{D}$, find the vector of HyperParameters $\\mathbf{\\lambda}^{*}$, which performes \"best\", i.e. minimises the expected loss function $\\mathcal{L}$ for the model $\\mathcal{A}_\\mathbf{\\lambda}$ on the test set of the data $D_\\mathrm{test}$:\n",
    "\n",
    "$$ \\mathbf{\\lambda}^{*} = \\mathop{\\mathrm{argmin}}_{\\mathbf{\\lambda} \\in \\mathbf{\\Lambda}} \\mathbb{E}_{D_\\mathrm{test} \\thicksim \\mathcal{D}} \\, \\left[ \\mathbf{V}\\left(\\mathcal{L}, \\mathcal{A}_\\mathbf{\\lambda}, D_\\mathrm{test}\\right) \\right]  $$\n",
    "\n",
    "In practice we have to approximate the expectation above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, we import the modules we want to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display                               \n",
    "from ipywidgets import interactive\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint, poisson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_SNR</th>\n",
       "      <th>STD_SNR</th>\n",
       "      <th>Kurtosis_SNR</th>\n",
       "      <th>Skewness_SNR</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.555184</td>\n",
       "      <td>61.719016</td>\n",
       "      <td>2.208808</td>\n",
       "      <td>3.662680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.358696</td>\n",
       "      <td>13.079034</td>\n",
       "      <td>13.312141</td>\n",
       "      <td>212.597029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.112876</td>\n",
       "      <td>62.070220</td>\n",
       "      <td>1.268206</td>\n",
       "      <td>1.082920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146.568562</td>\n",
       "      <td>82.394624</td>\n",
       "      <td>-0.274902</td>\n",
       "      <td>-1.121848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.071070</td>\n",
       "      <td>29.760400</td>\n",
       "      <td>5.318767</td>\n",
       "      <td>28.698048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32.919732</td>\n",
       "      <td>65.094197</td>\n",
       "      <td>1.605538</td>\n",
       "      <td>0.871364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34.101171</td>\n",
       "      <td>62.577395</td>\n",
       "      <td>1.890020</td>\n",
       "      <td>2.572133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.107860</td>\n",
       "      <td>66.321825</td>\n",
       "      <td>1.456423</td>\n",
       "      <td>1.335182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>176.119565</td>\n",
       "      <td>59.737720</td>\n",
       "      <td>-1.785377</td>\n",
       "      <td>2.940913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>183.622910</td>\n",
       "      <td>79.932815</td>\n",
       "      <td>-1.326647</td>\n",
       "      <td>0.346712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mean_SNR    STD_SNR  Kurtosis_SNR  Skewness_SNR  Class\n",
       "0   27.555184  61.719016      2.208808      3.662680      1\n",
       "1    1.358696  13.079034     13.312141    212.597029      1\n",
       "2   73.112876  62.070220      1.268206      1.082920      1\n",
       "3  146.568562  82.394624     -0.274902     -1.121848      1\n",
       "4    6.071070  29.760400      5.318767     28.698048      1\n",
       "5   32.919732  65.094197      1.605538      0.871364      1\n",
       "6   34.101171  62.577395      1.890020      2.572133      1\n",
       "7   50.107860  66.321825      1.456423      1.335182      1\n",
       "8  176.119565  59.737720     -1.785377      2.940913      1\n",
       "9  183.622910  79.932815     -1.326647      0.346712      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/Pulsar_data.csv')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We then divide the dataset in input features (X) and target (y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3278, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_SNR</th>\n",
       "      <th>STD_SNR</th>\n",
       "      <th>Kurtosis_SNR</th>\n",
       "      <th>Skewness_SNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>159.849498</td>\n",
       "      <td>76.740010</td>\n",
       "      <td>-0.575016</td>\n",
       "      <td>-0.941293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>4.243311</td>\n",
       "      <td>26.746490</td>\n",
       "      <td>7.110978</td>\n",
       "      <td>52.701218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>1.015050</td>\n",
       "      <td>10.449662</td>\n",
       "      <td>15.593479</td>\n",
       "      <td>316.011541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2.235786</td>\n",
       "      <td>19.071848</td>\n",
       "      <td>9.659137</td>\n",
       "      <td>99.294390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>2.266722</td>\n",
       "      <td>15.512103</td>\n",
       "      <td>9.062942</td>\n",
       "      <td>99.652157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>121.404682</td>\n",
       "      <td>47.965569</td>\n",
       "      <td>0.663053</td>\n",
       "      <td>1.203139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>35.209866</td>\n",
       "      <td>60.573157</td>\n",
       "      <td>1.635995</td>\n",
       "      <td>1.609377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>199.577759</td>\n",
       "      <td>58.656643</td>\n",
       "      <td>-1.862320</td>\n",
       "      <td>2.391870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>0.663043</td>\n",
       "      <td>8.571517</td>\n",
       "      <td>23.415092</td>\n",
       "      <td>655.614875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>3.112876</td>\n",
       "      <td>16.855717</td>\n",
       "      <td>8.301954</td>\n",
       "      <td>90.378150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mean_SNR    STD_SNR  Kurtosis_SNR  Skewness_SNR\n",
       "233   159.849498  76.740010     -0.575016     -0.941293\n",
       "831     4.243311  26.746490      7.110978     52.701218\n",
       "2658    1.015050  10.449662     15.593479    316.011541\n",
       "2495    2.235786  19.071848      9.659137     99.294390\n",
       "2603    2.266722  15.512103      9.062942     99.652157\n",
       "111   121.404682  47.965569      0.663053      1.203139\n",
       "1370   35.209866  60.573157      1.635995      1.609377\n",
       "1124  199.577759  58.656643     -1.862320      2.391870\n",
       "2170    0.663043   8.571517     23.415092    655.614875\n",
       "2177    3.112876  16.855717      8.301954     90.378150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns='Class')\n",
    "y = df['Class']\n",
    "feature_names = df.columns.tolist()[:-1]\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=42)\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And check out the y values (which turns out to be balanced):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233     1\n",
       "831     1\n",
       "2658    0\n",
       "2495    0\n",
       "2603    0\n",
       "111     1\n",
       "1370    1\n",
       "1124    1\n",
       "2170    0\n",
       "2177    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1319\n",
       "1    1303\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part A: Naïve Approach\n",
    "\n",
    "- Manual configuration\n",
    "- _\"[Babysitting is also known as Trial & Error or Grad Student Descent in the academic field](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/)\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feddba35729048f3bcb4792c29e918f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='max_depth', max=10, min=1), IntSlider(value=1, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fit_and_grapth_estimator(estimator):\n",
    "    \n",
    "    estimator.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy = accuracy_score(y_train, estimator.predict(X_train))\n",
    "    print(f'Training Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    class_names = [str(i) for i in range(y_train.nunique())]\n",
    "    graph = Source(tree.export_graphviz(estimator, \n",
    "                                        out_file=None, \n",
    "                                        feature_names=feature_names, \n",
    "                                        class_names=class_names, \n",
    "                                        filled = True))\n",
    "    display(SVG(graph.pipe(format='svg')))\n",
    "    return estimator\n",
    "\n",
    "\n",
    "def plot_tree(max_depth=1, min_samples_leaf=1):\n",
    "    \n",
    "    estimator = DecisionTreeClassifier(random_state=42, \n",
    "                                       max_depth=max_depth, \n",
    "                                       min_samples_leaf=min_samples_leaf)\n",
    "    \n",
    "    return fit_and_grapth_estimator(estimator)\n",
    "\n",
    "display(interactive(plot_tree, \n",
    "                    max_depth=(1, 10, 1), \n",
    "                    min_samples_leaf=(1, 100, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__(Test this interactively in notebook)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And test this configuration out on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Manual: 0.8201\n"
     ]
    }
   ],
   "source": [
    "clf_manual = DecisionTreeClassifier(random_state=42, \n",
    "                                    max_depth=10, \n",
    "                                    min_samples_leaf=5)\n",
    "\n",
    "clf_manual.fit(X_train, y_train)\n",
    "accuracy_manual = accuracy_score(y_test, clf_manual.predict(X_test))\n",
    "print(f'Accuracy Manual: {accuracy_manual:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part B: Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Grid Search: \n",
    "\n",
    "- _full factorial design_ \n",
    "- Cartesian product\n",
    "- Curse of dimensionality (grows exponentially)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![title](./images/GridSearch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__[Grid Search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\n",
    ")__ with Scikit Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "parameters_GridSearch = {'max_depth':[1, 10, 100], \n",
    "                         'min_samples_leaf':[1, 10, 100],\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "clf_DecisionTree = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "GridSearch = GridSearchCV(clf_DecisionTree, \n",
    "                          parameters_GridSearch, \n",
    "                          cv=5, \n",
    "                          return_train_score=True, \n",
    "                          refit=True, \n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "GridSearch.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "GridSearch_results = pd.DataFrame(GridSearch.cv_results_)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: \tBest parameters:  {'max_depth': 1, 'min_samples_leaf': 1} , Best scores: 0.8551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Grid Search: \\tBest parameters: \", GridSearch.best_params_, f\", Best scores: {GridSearch.best_score_:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 100}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006219</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.822857</td>\n",
       "      <td>0.858779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841729</td>\n",
       "      <td>0.011991</td>\n",
       "      <td>8</td>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.948021</td>\n",
       "      <td>0.954242</td>\n",
       "      <td>0.962345</td>\n",
       "      <td>0.957102</td>\n",
       "      <td>0.955568</td>\n",
       "      <td>0.004633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005722</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.845714</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.853053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846300</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>6</td>\n",
       "      <td>0.896042</td>\n",
       "      <td>0.898903</td>\n",
       "      <td>0.898475</td>\n",
       "      <td>0.893232</td>\n",
       "      <td>0.895615</td>\n",
       "      <td>0.896453</td>\n",
       "      <td>0.002066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 100}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 100, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.796190</td>\n",
       "      <td>0.841603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824190</td>\n",
       "      <td>0.015056</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005417</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 100, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.845714</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845154</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>7</td>\n",
       "      <td>0.896996</td>\n",
       "      <td>0.899857</td>\n",
       "      <td>0.898475</td>\n",
       "      <td>0.894185</td>\n",
       "      <td>0.896568</td>\n",
       "      <td>0.897216</td>\n",
       "      <td>0.001909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003583</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 100, 'min_samples_leaf': 100}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.002779      0.000164         0.000809        0.000059   \n",
       "1       0.002379      0.000035         0.000714        0.000037   \n",
       "2       0.002213      0.000125         0.000657        0.000036   \n",
       "3       0.006219      0.000102         0.000626        0.000005   \n",
       "4       0.005722      0.000068         0.000626        0.000002   \n",
       "5       0.003791      0.000177         0.000607        0.000023   \n",
       "6       0.006216      0.000127         0.000576        0.000003   \n",
       "7       0.005417      0.000117         0.000572        0.000001   \n",
       "8       0.003583      0.000097         0.000585        0.000033   \n",
       "\n",
       "  param_max_depth param_min_samples_leaf  \\\n",
       "0               1                      1   \n",
       "1               1                     10   \n",
       "2               1                    100   \n",
       "3              10                      1   \n",
       "4              10                     10   \n",
       "5              10                    100   \n",
       "6             100                      1   \n",
       "7             100                     10   \n",
       "8             100                    100   \n",
       "\n",
       "                                        params  split0_test_score  \\\n",
       "0      {'max_depth': 1, 'min_samples_leaf': 1}           0.849524   \n",
       "1     {'max_depth': 1, 'min_samples_leaf': 10}           0.849524   \n",
       "2    {'max_depth': 1, 'min_samples_leaf': 100}           0.849524   \n",
       "3     {'max_depth': 10, 'min_samples_leaf': 1}           0.847619   \n",
       "4    {'max_depth': 10, 'min_samples_leaf': 10}           0.845714   \n",
       "5   {'max_depth': 10, 'min_samples_leaf': 100}           0.849524   \n",
       "6    {'max_depth': 100, 'min_samples_leaf': 1}           0.826667   \n",
       "7   {'max_depth': 100, 'min_samples_leaf': 10}           0.845714   \n",
       "8  {'max_depth': 100, 'min_samples_leaf': 100}           0.849524   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "1           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "2           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "3           0.822857           0.858779  ...         0.841729        0.011991   \n",
       "4           0.847619           0.853053  ...         0.846300        0.008757   \n",
       "5           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "6           0.796190           0.841603  ...         0.824190        0.015056   \n",
       "7           0.849524           0.854962  ...         0.845154        0.009863   \n",
       "8           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                1            0.862184            0.858369   \n",
       "1                1            0.862184            0.858369   \n",
       "2                1            0.862184            0.858369   \n",
       "3                8            0.956128            0.948021   \n",
       "4                6            0.896042            0.898903   \n",
       "5                1            0.862184            0.858369   \n",
       "6                9            1.000000            1.000000   \n",
       "7                7            0.896996            0.899857   \n",
       "8                1            0.862184            0.858369   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.858913            0.859390            0.860343   \n",
       "1            0.858913            0.859390            0.860343   \n",
       "2            0.858913            0.859390            0.860343   \n",
       "3            0.954242            0.962345            0.957102   \n",
       "4            0.898475            0.893232            0.895615   \n",
       "5            0.858913            0.859390            0.860343   \n",
       "6            1.000000            1.000000            1.000000   \n",
       "7            0.898475            0.894185            0.896568   \n",
       "8            0.858913            0.859390            0.860343   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.859840         0.001340  \n",
       "1          0.859840         0.001340  \n",
       "2          0.859840         0.001340  \n",
       "3          0.955568         0.004633  \n",
       "4          0.896453         0.002066  \n",
       "5          0.859840         0.001340  \n",
       "6          1.000000         0.000000  \n",
       "7          0.897216         0.001909  \n",
       "8          0.859840         0.001340  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "clf_GridSearch = GridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Manual:      0.8201\n",
      "Accuracy Grid Search: 0.8430\n"
     ]
    }
   ],
   "source": [
    "accuracy_GridSearch = accuracy_score(y_test, clf_GridSearch.predict(X_test))\n",
    "print(f'Accuracy Manual:      {accuracy_manual:.4f}')\n",
    "print(f'Accuracy Grid Search: {accuracy_GridSearch:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part C: Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $B$ function evaluations, $N$ hyperparameters, $y$ number of different values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y_{\\mathrm{Grid Search}} = B^{1/N}, \\quad y_{\\mathrm{Random Search}} = B  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/RandomSearch.png\" alt=\"Random Search\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- _\"This failure of grid search is the rule rather than the exception in high dimensional\n",
    "hyper-parameter optimization\"_ [Bergstra, 2012]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- useful baseline because (almost) no assumptions about the ML algorithm being optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__[Random Search](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)__ with __[Scikit Learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)__ using __[Scipy Stats](https://docs.scipy.org/doc/scipy/reference/stats.html)__ as PDFs for the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "parameters_RandomSearch = {'max_depth': poisson(25), \n",
    "                           'min_samples_leaf': randint(1, 100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# run randomized search\n",
    "n_iter_search = 9\n",
    "RandomSearch = RandomizedSearchCV(clf_DecisionTree, \n",
    "                                  param_distributions=parameters_RandomSearch, \n",
    "                                  n_iter=n_iter_search, \n",
    "                                  cv=5, \n",
    "                                  return_train_score=True,\n",
    "                                  random_state=42,\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# fit the random search instance\n",
    "RandomSearch.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search: \tBest parameters:  {'max_depth': 26, 'min_samples_leaf': 83} , Best scores: 0.855\n"
     ]
    }
   ],
   "source": [
    "RandomSearch_results = pd.DataFrame(RandomSearch.cv_results_)                 \n",
    "print(\"Random Search: \\tBest parameters: \", RandomSearch.best_params_, f\", Best scores: {RandomSearch.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005123</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>23</td>\n",
       "      <td>72</td>\n",
       "      <td>{'max_depth': 23, 'min_samples_leaf': 72}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854308</td>\n",
       "      <td>0.010440</td>\n",
       "      <td>7</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>26</td>\n",
       "      <td>83</td>\n",
       "      <td>{'max_depth': 26, 'min_samples_leaf': 83}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>{'max_depth': 17, 'min_samples_leaf': 24}</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.860952</td>\n",
       "      <td>0.868321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854310</td>\n",
       "      <td>0.012162</td>\n",
       "      <td>6</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.879351</td>\n",
       "      <td>0.878456</td>\n",
       "      <td>0.875596</td>\n",
       "      <td>0.881792</td>\n",
       "      <td>0.878146</td>\n",
       "      <td>0.002373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>27</td>\n",
       "      <td>88</td>\n",
       "      <td>{'max_depth': 27, 'min_samples_leaf': 88}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004194</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>31</td>\n",
       "      <td>64</td>\n",
       "      <td>{'max_depth': 31, 'min_samples_leaf': 64}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.861296</td>\n",
       "      <td>0.860031</td>\n",
       "      <td>0.001460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>27</td>\n",
       "      <td>89</td>\n",
       "      <td>{'max_depth': 27, 'min_samples_leaf': 89}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.860343</td>\n",
       "      <td>0.859840</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_depth': 22, 'min_samples_leaf': 42}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.836190</td>\n",
       "      <td>0.856870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845540</td>\n",
       "      <td>0.015574</td>\n",
       "      <td>9</td>\n",
       "      <td>0.866476</td>\n",
       "      <td>0.865999</td>\n",
       "      <td>0.862726</td>\n",
       "      <td>0.865110</td>\n",
       "      <td>0.864156</td>\n",
       "      <td>0.864893</td>\n",
       "      <td>0.001343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>21</td>\n",
       "      <td>62</td>\n",
       "      <td>{'max_depth': 21, 'min_samples_leaf': 62}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850500</td>\n",
       "      <td>0.009778</td>\n",
       "      <td>8</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.861296</td>\n",
       "      <td>0.860031</td>\n",
       "      <td>0.001460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_leaf': 64}</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.859390</td>\n",
       "      <td>0.861296</td>\n",
       "      <td>0.860031</td>\n",
       "      <td>0.001460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.005123      0.000182         0.000790        0.000066   \n",
       "1       0.004545      0.000309         0.000705        0.000110   \n",
       "2       0.005211      0.000051         0.000610        0.000001   \n",
       "3       0.004039      0.000077         0.000629        0.000027   \n",
       "4       0.004194      0.000057         0.000586        0.000007   \n",
       "5       0.003895      0.000070         0.000584        0.000002   \n",
       "6       0.004551      0.000070         0.000585        0.000007   \n",
       "7       0.004242      0.000145         0.000642        0.000124   \n",
       "8       0.004201      0.000084         0.000618        0.000064   \n",
       "\n",
       "  param_max_depth param_min_samples_leaf  \\\n",
       "0              23                     72   \n",
       "1              26                     83   \n",
       "2              17                     24   \n",
       "3              27                     88   \n",
       "4              31                     64   \n",
       "5              27                     89   \n",
       "6              22                     42   \n",
       "7              21                     62   \n",
       "8              20                     64   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "0  {'max_depth': 23, 'min_samples_leaf': 72}           0.849524   \n",
       "1  {'max_depth': 26, 'min_samples_leaf': 83}           0.849524   \n",
       "2  {'max_depth': 17, 'min_samples_leaf': 24}           0.847619   \n",
       "3  {'max_depth': 27, 'min_samples_leaf': 88}           0.849524   \n",
       "4  {'max_depth': 31, 'min_samples_leaf': 64}           0.849524   \n",
       "5  {'max_depth': 27, 'min_samples_leaf': 89}           0.849524   \n",
       "6  {'max_depth': 22, 'min_samples_leaf': 42}           0.849524   \n",
       "7  {'max_depth': 21, 'min_samples_leaf': 62}           0.849524   \n",
       "8  {'max_depth': 20, 'min_samples_leaf': 64}           0.849524   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0           0.862857           0.862595  ...         0.854308        0.010440   \n",
       "1           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "2           0.860952           0.868321  ...         0.854310        0.012162   \n",
       "3           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "4           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "5           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "6           0.836190           0.856870  ...         0.845540        0.015574   \n",
       "7           0.840000           0.862595  ...         0.850500        0.009778   \n",
       "8           0.862857           0.862595  ...         0.855072        0.009121   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                7            0.862184            0.858369   \n",
       "1                1            0.862184            0.858369   \n",
       "2                6            0.875536            0.879351   \n",
       "3                1            0.862184            0.858369   \n",
       "4                1            0.862184            0.858369   \n",
       "5                1            0.862184            0.858369   \n",
       "6                9            0.866476            0.865999   \n",
       "7                8            0.862184            0.858369   \n",
       "8                1            0.862184            0.858369   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.858913            0.859390            0.860343   \n",
       "1            0.858913            0.859390            0.860343   \n",
       "2            0.878456            0.875596            0.881792   \n",
       "3            0.858913            0.859390            0.860343   \n",
       "4            0.858913            0.859390            0.861296   \n",
       "5            0.858913            0.859390            0.860343   \n",
       "6            0.862726            0.865110            0.864156   \n",
       "7            0.858913            0.859390            0.861296   \n",
       "8            0.858913            0.859390            0.861296   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.859840         0.001340  \n",
       "1          0.859840         0.001340  \n",
       "2          0.878146         0.002373  \n",
       "3          0.859840         0.001340  \n",
       "4          0.860031         0.001460  \n",
       "5          0.859840         0.001340  \n",
       "6          0.864893         0.001343  \n",
       "7          0.860031         0.001460  \n",
       "8          0.860031         0.001460  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomSearch_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Manual:        0.8201\n",
      "Accuracy Grid search:   0.8430\n",
      "Accuracy Random Search: 0.8430\n"
     ]
    }
   ],
   "source": [
    "clf_RandomSearch = RandomSearch.best_estimator_\n",
    "\n",
    "accuracy_RandomSearch = accuracy_score(y_test, clf_RandomSearch.predict(X_test))\n",
    "print(f'Accuracy Manual:        {accuracy_manual:.4f}')\n",
    "print(f'Accuracy Grid search:   {accuracy_GridSearch:.4f}')\n",
    "print(f'Accuracy Random Search: {accuracy_RandomSearch:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part D: Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Expensive black box functions $\\Rightarrow$ need of smart guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Probabilistic Surrogate Model (to be fitted)  \n",
    "   - Often Gaussian Processes \n",
    "2. Acquisition function  \n",
    "   - Exploitation / Exploration  \n",
    "   - Cheap to Computer\n",
    "  \n",
    "_[Brochu, Cora, de Freitas, 2010]_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./images/BO1.png\" alt=\"Bayesian Optimization 1\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./images/BO2.png\" alt=\"Bayesian Optimization 2\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./images/comparison_rs_bo.png\" alt=\"BO vs. RS\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "__[Bayesian Optimization](https://arxiv.org/pdf/1012.2599v1.pdf)__ with the Python package __[BayesianOptimization](https://github.com/fmfn/BayesianOptimization)__:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def DecisionTree_CrossValidation(max_depth, min_samples_leaf, data, targets):\n",
    "    \"\"\"Decision Tree cross validation.\n",
    "       Fits a Decision Tree with the given paramaters to the target \n",
    "       given data, calculated a CV accuracy score and returns the mean.\n",
    "       The goal is to find combinations of max_depth, min_samples_leaf \n",
    "       that maximize the accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    estimator = DecisionTreeClassifier(random_state=42, \n",
    "                                       max_depth=max_depth, \n",
    "                                       min_samples_leaf=min_samples_leaf)\n",
    "    \n",
    "    cval = cross_val_score(estimator, data, targets, scoring='accuracy', cv=5)\n",
    "    \n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def optimize_DecisionTree(data, targets, pars, n_iter=5):\n",
    "    \"\"\"Apply Bayesian Optimization to Decision Tree parameters.\"\"\"\n",
    "    \n",
    "    def crossval_wrapper(max_depth, min_samples_leaf):\n",
    "        \"\"\"Wrapper of Decision Tree cross validation. \n",
    "           Notice how we ensure max_depth, min_samples_leaf \n",
    "           are casted to integer before we pass them along.\n",
    "        \"\"\"\n",
    "        return DecisionTree_CrossValidation(max_depth=int(max_depth), \n",
    "                                            min_samples_leaf=int(min_samples_leaf), \n",
    "                                            data=data, \n",
    "                                            targets=targets)\n",
    "\n",
    "    optimizer = BayesianOptimization(f=crossval_wrapper, \n",
    "                                     pbounds=pars, \n",
    "                                     random_state=42, \n",
    "                                     verbose=2)\n",
    "    optimizer.maximize(init_points=4, n_iter=n_iter)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8551  \u001b[0m | \u001b[0m 38.08   \u001b[0m | \u001b[0m 95.12   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.849   \u001b[0m | \u001b[0m 73.47   \u001b[0m | \u001b[0m 60.27   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8524  \u001b[0m | \u001b[0m 16.45   \u001b[0m | \u001b[0m 16.44   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8551  \u001b[0m | \u001b[0m 6.75    \u001b[0m | \u001b[0m 86.75   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8551  \u001b[0m | \u001b[0m 1.56    \u001b[0m | \u001b[0m 99.21   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8551  \u001b[0m | \u001b[0m 2.084   \u001b[0m | \u001b[0m 88.69   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8551  \u001b[0m | \u001b[0m 1.206   \u001b[0m | \u001b[0m 97.77   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8551  \u001b[0m | \u001b[0m 1.452   \u001b[0m | \u001b[0m 98.8    \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8551  \u001b[0m | \u001b[0m 1.165   \u001b[0m | \u001b[0m 98.39   \u001b[0m |\n",
      "=================================================\n",
      "{'target': 0.8550716103235187, 'params': {'max_depth': 38.07947176588889, 'min_samples_leaf': 95.1207163345817}}\n"
     ]
    }
   ],
   "source": [
    "parameters_BayesianOptimization = {\"max_depth\": (1, 100), \n",
    "                                   \"min_samples_leaf\": (1, 100),\n",
    "                                  }\n",
    "\n",
    "BayesianOptimization = optimize_DecisionTree(X_train, \n",
    "                                             y_train, \n",
    "                                             parameters_BayesianOptimization, \n",
    "                                             n_iter=5)\n",
    "print(BayesianOptimization.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "params = BayesianOptimization.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "for key, val in params.items():\n",
    "    params[key] = int(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "clf_BO = DecisionTreeClassifier(random_state=42, **params)\n",
    "clf_BO = clf_BO.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Manual:                0.8201\n",
      "Accuracy Grid Search:           0.8430\n",
      "Accuracy Random Search:         0.8430\n",
      "Accuracy Bayesian Optimization: 0.8430\n"
     ]
    }
   ],
   "source": [
    "accuracy_BayesianOptimization = accuracy_score(y_test, clf_BO.predict(X_test))\n",
    "print(f'Accuracy Manual:                {accuracy_manual:.4f}')\n",
    "print(f'Accuracy Grid Search:           {accuracy_GridSearch:.4f}')\n",
    "print(f'Accuracy Random Search:         {accuracy_RandomSearch:.4f}')\n",
    "print(f'Accuracy Bayesian Optimization: {accuracy_BayesianOptimization:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part D: Full Scan over Parameter Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Only possible in low-dimensional space, slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "max_depth_array = np.arange(1, 30)\n",
    "min_samples_leaf_array = np.arange(2, 31)\n",
    "Z = np.zeros((len(max_depth_array), len(min_samples_leaf_array)))\n",
    "\n",
    "for i, max_depth in enumerate(max_depth_array):\n",
    "    for j, min_samples_leaf in enumerate(min_samples_leaf_array):\n",
    "        \n",
    "        clf = DecisionTreeClassifier(random_state=42, \n",
    "                                     max_depth=max_depth, \n",
    "                                     min_samples_leaf=\n",
    "                                     min_samples_leaf)\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "        Z[i, j] = acc\n",
    "        \n",
    "# Notice: have to transpose Z to match up with imshow\n",
    "Z = Z.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# notice that we are setting the extent and origin keywords\n",
    "CS = ax.imshow(Z, extent=[1, 30, 2, 31], cmap='viridis', origin='lower')\n",
    "ax.set(xlabel='max_depth', ylabel='min_samples_leaf')\n",
    "\n",
    "fig.colorbar(CS);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sum up:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./images/Chart.png\" alt=\"Chart\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__[Guide To Hyperparameters Search For Deep Learning Models](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part E: New Methods\n",
    "\n",
    "Bayesian Optimization meets HyperBand (BOHB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "HyperBand:\n",
    "\n",
    "\n",
    "<img src=\"./images/sh.gif\" alt=\"BO vs. RS\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./images/comparison_rs_bo.png\" alt=\"BO vs. RS\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./images/comparison-1.png\" alt=\"BOHB\" width=\"600\"/>\n",
    "\n",
    "__[BOHB: Robust and Efficient Hyperparameter Optimization at Scale](https://www.automl.org/blog_bohb/)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part F: New Software\n",
    "\n",
    "Optuna (see code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from optuna.pruners import MedianPruner\n",
    "import lightgbm as lgb\n",
    "\n",
    "#%%\n",
    "\n",
    "# lgb_data_train = ...           # Here you have to come with a model yourself!\n",
    "lgb_data_train = lgb.Dataset(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    boosting_types = [\"gbdt\", \"rf\", \"dart\"]\n",
    "    boosting_type = trial.suggest_categorical(\"boosting_type\", boosting_types)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": 'auc',\n",
    "        \"boosting\": boosting_type,\n",
    "        \"max_depth\": 5,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 63),\n",
    "        \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 1e-5, 10),\n",
    "        \"scale_pos_weight\": trial.suggest_uniform(\"scale_pos_weight\", 10.0, 30.0),\n",
    "        \"bagging_freq\": 1, \"bagging_fraction\": 0.6,\n",
    "        \"verbosity\": -1\n",
    "    }\n",
    "\n",
    "    N_iterations_max = 10_000\n",
    "    early_stopping_rounds = 50\n",
    "\n",
    "    if boosting_type == \"dart\":\n",
    "        N_iterations_max = 100\n",
    "        early_stopping_rounds = None\n",
    "\n",
    "    cv_res = lgb.cv(\n",
    "        params,\n",
    "        lgb_data_train,\n",
    "        num_boost_round=N_iterations_max,\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        verbose_eval=False,\n",
    "        seed=42,\n",
    "        callbacks=[LightGBMPruningCallback(trial, \"auc\")],\n",
    "    )\n",
    "\n",
    "    num_boost_round = len(cv_res[\"auc-mean\"])\n",
    "    trial.set_user_attr(\"num_boost_round\", num_boost_round)\n",
    "\n",
    "    return cv_res[\"auc-mean\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-08 15:46:00,530]\u001b[0m A new study created in memory with name: no-name-5109b564-59be-4590-9951-bd62f8c2dfc9\u001b[0m\n",
      "/opt/anaconda3/lib/python3.7/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d8803f65b345af92d434f022af8441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-08 15:46:00,883]\u001b[0m Trial 0 finished with value: 0.9257274934861961 and parameters: {'boosting_type': 'rf', 'max_depth': 39, 'min_child_weight': 8.632008168602535e-05, 'scale_pos_weight': 13.119890406724053}. Best is trial 0 with value: 0.9257274934861961.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:01,174]\u001b[0m Trial 1 finished with value: 0.925645717219157 and parameters: {'boosting_type': 'rf', 'max_depth': 45, 'min_child_weight': 1.3289448722869181e-05, 'scale_pos_weight': 29.398197043239886}. Best is trial 0 with value: 0.9257274934861961.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:01,501]\u001b[0m Trial 2 finished with value: 0.9327382743380188 and parameters: {'boosting_type': 'gbdt', 'max_depth': 13, 'min_child_weight': 0.0006690421166498799, 'scale_pos_weight': 20.495128632644757}. Best is trial 2 with value: 0.9327382743380188.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:01,826]\u001b[0m Trial 3 finished with value: 0.9293024673628942 and parameters: {'boosting_type': 'dart', 'max_depth': 10, 'min_child_weight': 0.0005660670699258885, 'scale_pos_weight': 17.327236865873836}. Best is trial 2 with value: 0.9327382743380188.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:02,069]\u001b[0m Trial 4 finished with value: 0.9261444485440651 and parameters: {'boosting_type': 'rf', 'max_depth': 33, 'min_child_weight': 0.035849855803404704, 'scale_pos_weight': 10.929008254399955}. Best is trial 2 with value: 0.9327382743380188.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:02,402]\u001b[0m Trial 5 finished with value: 0.9311118522518811 and parameters: {'boosting_type': 'gbdt', 'max_depth': 60, 'min_child_weight': 6.220025976819156, 'scale_pos_weight': 26.16794696232922}. Best is trial 2 with value: 0.9327382743380188.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:02,552]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:02,696]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:02,839]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:02,986]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:03,049]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:03,376]\u001b[0m Trial 11 finished with value: 0.9309290578399502 and parameters: {'boosting_type': 'gbdt', 'max_depth': 63, 'min_child_weight': 6.894420684704665, 'scale_pos_weight': 25.370137676514304}. Best is trial 2 with value: 0.9327382743380188.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:03,727]\u001b[0m Trial 12 finished with value: 0.9323419999728675 and parameters: {'boosting_type': 'gbdt', 'max_depth': 63, 'min_child_weight': 0.38601839366790247, 'scale_pos_weight': 23.675597363736365}. Best is trial 2 with value: 0.9327382743380188.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:04,075]\u001b[0m Trial 13 finished with value: 0.9327630495788028 and parameters: {'boosting_type': 'gbdt', 'max_depth': 21, 'min_child_weight': 0.47333235522568584, 'scale_pos_weight': 22.116723260828707}. Best is trial 13 with value: 0.9327630495788028.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:04,438]\u001b[0m Trial 14 finished with value: 0.9318985480712734 and parameters: {'boosting_type': 'gbdt', 'max_depth': 20, 'min_child_weight': 0.0018017260723627204, 'scale_pos_weight': 20.87074372077165}. Best is trial 13 with value: 0.9327630495788028.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:04,789]\u001b[0m Trial 15 finished with value: 0.933907588579396 and parameters: {'boosting_type': 'gbdt', 'max_depth': 23, 'min_child_weight': 0.5262050790257533, 'scale_pos_weight': 17.101924194245463}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:05,135]\u001b[0m Trial 16 finished with value: 0.9323761434494685 and parameters: {'boosting_type': 'gbdt', 'max_depth': 25, 'min_child_weight': 0.7139629318981857, 'scale_pos_weight': 15.599819505406096}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:05,226]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:05,559]\u001b[0m Trial 18 finished with value: 0.9320047563876231 and parameters: {'boosting_type': 'gbdt', 'max_depth': 20, 'min_child_weight': 0.07473651026301241, 'scale_pos_weight': 18.745829052448148}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:05,733]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 61.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:06,086]\u001b[0m Trial 20 finished with value: 0.9328372233375839 and parameters: {'boosting_type': 'gbdt', 'max_depth': 21, 'min_child_weight': 1.5423777057795445, 'scale_pos_weight': 13.233732216784787}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:06,377]\u001b[0m Trial 21 finished with value: 0.9321245240568861 and parameters: {'boosting_type': 'gbdt', 'max_depth': 22, 'min_child_weight': 1.5417332097862932, 'scale_pos_weight': 10.107893557559724}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:06,722]\u001b[0m Trial 22 finished with value: 0.9323386454194766 and parameters: {'boosting_type': 'gbdt', 'max_depth': 26, 'min_child_weight': 0.13230118984954353, 'scale_pos_weight': 12.488404178785878}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:06,910]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 66.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:07,290]\u001b[0m Trial 24 finished with value: 0.9324599798628743 and parameters: {'boosting_type': 'gbdt', 'max_depth': 29, 'min_child_weight': 0.22938248553821958, 'scale_pos_weight': 18.52693332188188}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:07,570]\u001b[0m Trial 25 finished with value: 0.9323709490119938 and parameters: {'boosting_type': 'gbdt', 'max_depth': 10, 'min_child_weight': 0.014223320052048582, 'scale_pos_weight': 11.577261921985883}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:07,709]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:08,045]\u001b[0m Trial 27 finished with value: 0.932944700613427 and parameters: {'boosting_type': 'gbdt', 'max_depth': 37, 'min_child_weight': 0.018459882906772026, 'scale_pos_weight': 17.679098751711575}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:08,406]\u001b[0m Trial 28 finished with value: 0.9327459260646458 and parameters: {'boosting_type': 'gbdt', 'max_depth': 38, 'min_child_weight': 0.006874274339719773, 'scale_pos_weight': 14.404674789343591}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:08,547]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 52.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:08,943]\u001b[0m Trial 30 finished with value: 0.9327176880494863 and parameters: {'boosting_type': 'gbdt', 'max_depth': 51, 'min_child_weight': 0.003257102075046086, 'scale_pos_weight': 17.435919490699508}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:09,077]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:09,230]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:09,585]\u001b[0m Trial 33 finished with value: 0.9326676138454196 and parameters: {'boosting_type': 'gbdt', 'max_depth': 23, 'min_child_weight': 2.9350751934489323, 'scale_pos_weight': 17.738460794183766}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:09,717]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:09,863]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:09,995]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:10,160]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:10,292]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:10,657]\u001b[0m Trial 39 finished with value: 0.9331977959415845 and parameters: {'boosting_type': 'gbdt', 'max_depth': 35, 'min_child_weight': 0.000341792895071912, 'scale_pos_weight': 10.091883058577956}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:10,800]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:11,163]\u001b[0m Trial 41 finished with value: 0.9330434512538387 and parameters: {'boosting_type': 'gbdt', 'max_depth': 36, 'min_child_weight': 0.0010904325188218595, 'scale_pos_weight': 10.103269089092729}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-08 15:46:11,522]\u001b[0m Trial 42 finished with value: 0.9330358105424482 and parameters: {'boosting_type': 'gbdt', 'max_depth': 35, 'min_child_weight': 0.0004148881183051914, 'scale_pos_weight': 10.017562759585447}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:11,680]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 56.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:11,834]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:12,195]\u001b[0m Trial 45 finished with value: 0.9329793149860837 and parameters: {'boosting_type': 'gbdt', 'max_depth': 41, 'min_child_weight': 0.001167290226730846, 'scale_pos_weight': 10.044747367447195}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:12,348]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 56.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:12,504]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:12,635]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:13,036]\u001b[0m Trial 49 finished with value: 0.9331977959415845 and parameters: {'boosting_type': 'gbdt', 'max_depth': 31, 'min_child_weight': 0.0029537732097114785, 'scale_pos_weight': 10.091379098007323}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:13,382]\u001b[0m Trial 50 finished with value: 0.9332437207336415 and parameters: {'boosting_type': 'gbdt', 'max_depth': 31, 'min_child_weight': 0.0036815043901656367, 'scale_pos_weight': 11.101495735354064}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:13,607]\u001b[0m Trial 51 pruned. Trial was pruned at iteration 80.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:13,743]\u001b[0m Trial 52 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:13,883]\u001b[0m Trial 53 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:14,231]\u001b[0m Trial 54 finished with value: 0.9326659755677553 and parameters: {'boosting_type': 'gbdt', 'max_depth': 32, 'min_child_weight': 0.005148615159009996, 'scale_pos_weight': 10.013233337332471}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:14,959]\u001b[0m Trial 55 finished with value: 0.932887914967943 and parameters: {'boosting_type': 'gbdt', 'max_depth': 35, 'min_child_weight': 0.0007769349556585813, 'scale_pos_weight': 10.919188105436339}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:15,090]\u001b[0m Trial 56 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:15,235]\u001b[0m Trial 57 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:15,372]\u001b[0m Trial 58 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:15,523]\u001b[0m Trial 59 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:15,885]\u001b[0m Trial 60 finished with value: 0.9326659755677553 and parameters: {'boosting_type': 'gbdt', 'max_depth': 32, 'min_child_weight': 0.0125312356630232, 'scale_pos_weight': 10.012683183019575}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:16,100]\u001b[0m Trial 61 pruned. Trial was pruned at iteration 78.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:16,236]\u001b[0m Trial 62 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:16,584]\u001b[0m Trial 63 finished with value: 0.9337278447512649 and parameters: {'boosting_type': 'gbdt', 'max_depth': 43, 'min_child_weight': 0.0025822330028222257, 'scale_pos_weight': 10.12268219759839}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:16,719]\u001b[0m Trial 64 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:16,863]\u001b[0m Trial 65 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:17,001]\u001b[0m Trial 66 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:17,145]\u001b[0m Trial 67 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:17,287]\u001b[0m Trial 68 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:17,427]\u001b[0m Trial 69 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:17,559]\u001b[0m Trial 70 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:17,704]\u001b[0m Trial 71 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:18,051]\u001b[0m Trial 72 finished with value: 0.9330532260771051 and parameters: {'boosting_type': 'gbdt', 'max_depth': 41, 'min_child_weight': 0.0010124114585983697, 'scale_pos_weight': 10.019540916241073}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:18,264]\u001b[0m Trial 73 pruned. Trial was pruned at iteration 78.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:18,403]\u001b[0m Trial 74 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:18,552]\u001b[0m Trial 75 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:18,693]\u001b[0m Trial 76 pruned. Trial was pruned at iteration 52.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:18,839]\u001b[0m Trial 77 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:19,188]\u001b[0m Trial 78 finished with value: 0.9332219468158403 and parameters: {'boosting_type': 'gbdt', 'max_depth': 48, 'min_child_weight': 0.00021426558938719107, 'scale_pos_weight': 10.049409464075314}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:19,321]\u001b[0m Trial 79 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:19,473]\u001b[0m Trial 80 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:19,822]\u001b[0m Trial 81 finished with value: 0.9335821924646988 and parameters: {'boosting_type': 'gbdt', 'max_depth': 40, 'min_child_weight': 8.589036966510786e-05, 'scale_pos_weight': 10.070391130777391}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:19,955]\u001b[0m Trial 82 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:20,107]\u001b[0m Trial 83 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:20,459]\u001b[0m Trial 84 finished with value: 0.9333552874637998 and parameters: {'boosting_type': 'gbdt', 'max_depth': 45, 'min_child_weight': 2.4458989204236287e-05, 'scale_pos_weight': 11.595407882622062}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:20,593]\u001b[0m Trial 85 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:20,736]\u001b[0m Trial 86 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:20,873]\u001b[0m Trial 87 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:21,020]\u001b[0m Trial 88 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:21,155]\u001b[0m Trial 89 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:21,297]\u001b[0m Trial 90 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:21,636]\u001b[0m Trial 91 finished with value: 0.932749962586399 and parameters: {'boosting_type': 'gbdt', 'max_depth': 38, 'min_child_weight': 0.0006070626829421298, 'scale_pos_weight': 10.455425864624141}. Best is trial 15 with value: 0.933907588579396.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:21,773]\u001b[0m Trial 92 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:21,921]\u001b[0m Trial 93 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:22,053]\u001b[0m Trial 94 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:22,198]\u001b[0m Trial 95 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:22,333]\u001b[0m Trial 96 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:22,480]\u001b[0m Trial 97 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:22,627]\u001b[0m Trial 98 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2022-05-08 15:46:22,792]\u001b[0m Trial 99 pruned. Trial was pruned at iteration 56.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=TPESampler(seed=42),\n",
    "    pruner=MedianPruner(n_warmup_steps=50),\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To see all info at the best trial use:  study.best_trial\n",
    "To print metric values for all trials:  study.best_trial.intermediate_values\n",
    "To see distributions from which optuna samples parameters:  study.best_trial.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'max_depth': 23,\n",
       " 'min_child_weight': 0.5262050790257533,\n",
       " 'scale_pos_weight': 17.101924194245463}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To simply get the optimized parameters:\n",
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "6aba6d678e50d757e9e1bf8fa8538a573156bd3852124f6ff591560922470a56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
